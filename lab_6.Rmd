---
title: "lab_6"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(kableExtra)
```

### 1) Grades

**The following anonymized data show the midterm and final exam grades (%) for eight students. The partial ANOVA table provides sum of squares and mean squares. What is the repeatability of grade performance?**

```{r}

grade_data <- data.frame(individual = (1:8),
                         midterm = c(78,84,94,82,58,62,81,80),
                         final = c(81,65,75,62,60,86,92,89))
  
sum(grade_data$midterm^2 + grade_data$final^2)

```


#### a) Calculate sA2from the mean squares and the sample size. What variance component does this quantity estimate?

\[
S_A^2 = \frac{MS_{groups} - MS_{error}}{n}
\]

```{r}

S_a2 <- (163.71-119.56)/2

```

The SA2 value we found was **`r S_a2`**. This variance component corresponds to the amount of variation associated with actual differences between individual students in performance on this kind of test. 

<!-- forced_linebreak -->
&nbsp; 

#### b) Calculate the repeatability using sA2and MSerror.


\[
repeatability = \frac{S_A^2}{S_A^2 + MS_{error}}
\]

```{r}

repeatability <- S_a2 / (S_a2 + 119.56)

```

The repeatability was **`r repeatability`**. 

<!-- forced_linebreak -->
&nbsp; 

#### c) Interpret the repeatability you just calculated. What fraction of the variance among test scores is estimated to reflect true differences among students in performance, and what fraction is measurement variance from test to test within students?

Higher repeatability values indicate that the majority of variation is based on differences between students in test-taking performance. Low repeatability indicates that most of the variation is due to random differences in performance for individual students between subsequent tests. 

The repeatability value we got was quite low, which indicates that most of the variation we observed is due to random error between subsequent test performance for individual students. We can visually check this by making a plot of the test performance for each student on the midterm and final:

```{r}

ggplot(data=grade_data) + 
  geom_point(aes(x=individual,y=midterm),col="red") +
  geom_point(aes(x=individual,y=final),col="blue") + 
  ggtitle("Test Performance by Student") + 
  xlab("Student ID") + 
  ylab("Test Grade") + 
  labs(caption="Test performance on midterm (red) and final (blue) tests across a set of 8 students.")

```

Looking at this plot seems to corroborate our conclusion above... For individual students, the difference in final vs. midterm performance seems larger than the difference on tests across students. 


<!-- forced_linebreak -->
&nbsp; 

#### d) What assumptions are you making when estimating repeatability to test scores? 

1) Measurements in each group are a random sample from the group population (in this case this seems reasonable since we probably have a population census of the class)

2) The variable is normally distributed in each of the k populations (this seems like a reasonable assumption but is difficult to validate with such a small sample size)

3) The variance is the same across all k populations

```{r}

var(grade_data$midterm)
var(grade_data$final)

```

These sample variances differ but not by a huge margin, and the sample size is pretty small, so it's difficult to say whether the population variances differ. 

4) Groups are randomly sampled (i.e. the 'final' and 'midterm' are valid random representatives of the total population of tests)

5) The group means have a normal distribution in the population.

<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 





### 2) Caffeine

**Many humans like the effect of caffeine, but it occurs in plants as a deterrent to herbivory by animals. Caffeine is also found in flower nectar, and nectar is meant as a reward for pollinators, not a deterrent. How does caffeine in nectar affect visitation by pollinators? Singaravelan et al. (2005) set up feeding stations where bees were offered a choice between a control solution with 20% sucrose or a caffeinated solution with 20% sucrose plus some quantity of caffeine. Over the course of the experiment, four different concentrations of caffeine were provided: 50, 100, 150, and 200 ppm. The response variable was the difference between the amount of nectar consumed from the caffeine feeders and that removed from the control feeders at the same station (in grams). Here are the data:**


```{r}

caffeine <- data.frame(
  ppm_50 = c(-0.4, 0.34, 0.19, 0.05, -0.14100),
  ppm_100 = c(0.01, -0.39, -0.08, -0.09, -0.31150),
  ppm_150 = c(0.65, 0.53, 0.39, -0.15, 0.46200),
  ppm_200 = c(0.24, 0.44, 0.13, 1.03, 0.05))

```

Does the mean amount of nectar taken depend on the concentration of caffeine in the nectar? Carry out ANOVA step by step in the following subsections:

<!-- forced_linebreak -->
&nbsp; 

#### a) State the null and alternate hypotheses appropriate to this question.

Ho: There is no difference in mean nectar consumption between groups based on the amount of caffeine in the nectar.

Ha: There is a difference in mean nectar consumption between at least some groups based on the amount of caffeine in the nectar.

<!-- forced_linebreak -->
&nbsp; 



#### b) Calculated the following summary statistics for each group: sample size, sample mean, sample standard deviation.

```{r}

stats <- data.frame(group = c("ppm_50","ppm_100","ppm_150","ppm_200"),
                    n = rep(5,4),
                    mean = c(mean(caffeine$ppm_50),mean(caffeine$ppm_100),mean(caffeine$ppm_150),mean(caffeine$ppm_200)),
                    stdev = c(sd(caffeine$ppm_50),sd(caffeine$ppm_100),sd(caffeine$ppm_150),sd(caffeine$ppm_200)))

kable(stats) %>% kable_styling()

```

<!-- forced_linebreak -->
&nbsp; 

Based on a quick look at these data, it might be hard to conclude that there's much going on here. In all four cases the standard deviation was greater than or almost equal to the absolute value of the mean, which might make it hard to demonstrate that the observed means are significantly different from zero (it may be hard to show that any of the nectar removal rates differ meaningfully from the control). 

#### c) What is the mean square error?

```{r}

sserr <- sum(stats$stdev^2 * (stats$n-1))
mserr <- sserr / (16)

```

The mean square error is **`r mserr`**.

<!-- forced_linebreak -->
&nbsp; 



#### d) How many degrees of freedom are associated with error?

The number of degrees of freedom associated with error is N - k, which here is 20 - 4 = **16**.

<!-- forced_linebreak -->
&nbsp; 



#### e) Calculate the estimate of the grand mean.

```{r}

mean_grand <- sum(stats$mean*stats$n) / sum(stats$n)

```

<!-- forced_linebreak -->
&nbsp; 



#### f) Calculate the group sum of squares.

```{r}

ss_group <- sum(stats$n * (stats$mean - mean_grand)^2)

```

The group sum of squares is **`r ss_group`**.

<!-- forced_linebreak -->
&nbsp; 



#### g.Calculate the group degrees of freedom and the group mean square.

The group degrees of freedom is 4-1 = **`r 3`**. 

```{r}

ms_group <- ss_group / 3

```

The group mean square is **`r ms_group`**.

<!-- forced_linebreak -->
&nbsp; 



#### h) What is F for this example?

```{r}

F_caffeine = ms_group / mserr

```

The F statistic here is **`r F_caffeine`**.

<!-- forced_linebreak -->
&nbsp; 



#### i) Find the P-value for this test?

```{r}

p_val_caffeine <- pf(F_caffeine, df1=3, df2=16, lower.tail=F)

```

The p-value for this ANOVA test is **`r p_val_caffeine`**.

<!-- forced_linebreak -->
&nbsp; 



#### j) Report your results in an ANOVA table.

```{r}

caffeine <- c(-0.4, 0.34, 0.19, 0.05, -0.14100, 0.01, -0.39, -0.08, -0.09, -0.31150, 0.65, 0.53, 0.39, -0.15, 0.46200, 0.24, 0.44, 0.13, 1.03, 0.05)
dft <- data.frame(visit = caffeine, group = c(rep("ppm_50",5),rep("ppm_100",5),rep("ppm_150",5),rep("ppm_200",5)))

caffeine_aov <- aov(visit ~ group, data=dft)

summary(caffeine_aov)

```

Because we found p_val = 0.023 < 0.05, we can reject the null hypothesis that there is no difference between the mean values for any of our groups. It appears that at least one pairing between treatments for nectar depletion rates in excess of the control rate show mean values which are significantly different. We will need to run a post-hoc test to determine for which treatments this is the case. 


<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 





### 3) Tukey

**Use the same data as the previous question, and carry out the Tukey-Kramer test to find which pairs of sample means differ from each other.Report your results in a table with the following columns: Group i label, Group j label, difference of sample means for group i and j, standard error, value of test statistic q, critical value of q, and your conclusion about the hypothesis being tested.**


```{r}

caffeine_thsd <- TukeyHSD(caffeine_aov)

caffeine_tukey <- data.frame(name_i = c("ppm_150", "ppm_200", "ppm_50", "ppm_200", "ppm_50", "ppm_50"),
                             name_j = c("ppm_100", "ppm_100", "ppm_100", "ppm_150", "ppm_150", "ppm_200"),
                             difference = as.numeric(caffeine_thsd$group[1:6,1]),
                             sterr = rep(0,6),
                             q_val = rep(0,6),
                             q_crit = rep(0,6),
                             p_val = rep(0,6),
                             conclusion = rep("0",6))

caffeine_q <- qtukey(1-as.numeric(caffeine_thsd$group[1:6,4]), nmeans = 4, df = 16)

sterr <- caffeine_q / caffeine_tukey$difference

caffeine_tukey$sterr <- rep(sterr[1],6)
caffeine_tukey$q_val <- caffeine_q
caffeine_tukey$q_crit <- rep(qtukey(0.95, nmeans=4, df=16),6)
caffeine_tukey$p_val <- as.numeric(caffeine_thsd$group[1:6,4])
caffeine_tukey$conclusion <- c("reject null","reject null","fail to reject null","fail to reject null","fail to reject null","fail to reject null")

kable(caffeine_tukey) %>% kable_styling()
```

Based on this analysis, we found a significant difference in mean difference over the control treatment for the 150 ppm and 100 ppm pair, and for the 200 ppm and 100 ppm pair. For these two test pairs we can conclude that there was a meaningful difference in response, but we can't for any other pairing. 


<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 




### 4) Precipitation

**Using the following data: Precipitation at Boston airport (inches)**

```{r}

boston_precip <- data.frame(
Year = c("1971 II","1972 I","1972 II","1973 I","1973 II","1974 I"),
Sat = c(0.83,4.66,3.03,3.69,2.35,3.18),
Sun = c(3.14,4.15,5.8,3.72,3.62,3.28),
Mon = c(4.2,3.4,2.29,4.29,3.56,1.82),
Tue = c(1.28,1.74,3.17,2.06,2.27,3.75),
Wed = c(1.16,3.91,3.5,3.04,4.46,2.07),
Thur = c(4.25,5.15,3.4,2.3,2.52,3.54),
Fri = c(2.08,5.06,3.04,4.26,3.36,2.27))

kable(boston_precip) %>% kable_styling()

# Pivot into a longer format with day as a variable, not observation
boston_precip_long <- boston_precip %>% pivot_longer(2:8, names_to = "Day", values_to = "Rain")

```

#### a. Find the mean and standard deviation for each day of the week.

```{r}

boston_stats <- boston_precip_long %>%
  mutate(Day = factor(Day, levels=c("Sat","Sun","Mon","Tue","Wed","Thur","Fri"))) %>%
  group_by(Day) %>%
  summarize(mean = mean(Rain),
            stdev = sd(Rain))

kable(boston_stats) %>% kable_styling()

```


<!-- forced_linebreak -->
&nbsp; 


#### b. Perform an analysis of variance to test the null hypothesis that precipitation does not vary by day of the week. Show the group and error sum of squares, the observed Fstatistic, and the critical F-value.

```{r}

boston_precip_daywise <- boston_precip_long %>%
  pivot_wider(names_from = "Year", values_from = "Rain")

kable(boston_precip_daywise) %>% kable_styling()

boston_aov <- aov(Rain ~ Day, data=boston_precip_long)
summary(boston_aov)

# Critical F value:
qf(0.95, df1=6, df2=28)

```

Because the p-value we got (0.323) is relatively large and much bigger than 0.05, we cannot reject the null hypothesis that the mean rainfall on each day of the week is the same. This is not surprising; it would be weird if we had found an effect here!


<!-- forced_linebreak -->
&nbsp; 


#### c. Repeat the analysis using data for Pittsburgh. The precipitation at Pittsburgh airport is
(inches):

```{r}

pitts_precip <- data.frame(
Year = c("1971 II","1972 I","1972 II","1973 I","1973 II","1974 I"),
Sat = c(1.64,2.2,2.75,2.23,3.65,4.96),
Sun = c(5.55,3.37,1.72,4.31,2.66,3),
Mon = c(3.19,0.78,2.34,2.02,3.95,2.61),
Tue = c(2.45,2.63,3.4,1.83,2.31,1.75),
Wed = c(1.44,2.32,3.68,4.35,1.85,2.7),
Thur = c(1.07,5.57,3.48,4.07,2.63,2.45),
Fri = c(1.66,2.8,2.5,2.66,1.11,4.06))

kable(pitts_precip) %>% kable_styling()

# Pivot into a longer format with day as a variable, not observation
pitts_precip_long <- pitts_precip %>% pivot_longer(2:8, names_to = "Day", values_to = "Rain")


pitts_stats <- pitts_precip_long %>%
  mutate(Day = factor(Day, levels=c("Sat","Sun","Mon","Tue","Wed","Thur","Fri"))) %>%
  group_by(Day) %>%
  summarize(mean = mean(Rain),
            stdev = sd(Rain))

kable(pitts_stats) %>% kable_styling()

pitts_aov <- aov(Rain ~ Day, data=pitts_precip_long)
summary(pitts_aov)

# Critical F value:
#    The critical F value is the same here, becuase alpha and both degrees of freedom are the same as before
qf(0.95, df1=6, df2=28)

```

This time we got an even larger overall p-value at 0.638. Again, this means we cannot reject the null hypothesis that there is no difference in rainfall across days. And again this makes sense!

<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 



### 5) Example ANOVA

**Assume that an analysis of variance is conducted for a study where there are N = 50 observations and k = 5 categories. Fill in the blanks in the following ANOVA table:**

```{r}

anova_5 <- data.frame(source = c("Group", "Error", "Total"),
                      'Sum of Squares' = c(0,2000,0),
                      'df' = c(0,0,0),
                      'Mean Squares' = c(116.3,0,NA),
                      F = c(NA,NA,NA),
                      P = c(NA,NA,NA))

kable(anova_5) %>% kable_styling()

```

**With alpha = 0.05, what is your conclusion regarding the null hypothesis that the means of the categories are equal?**

```{r}

# First, lets set the degrees of freedom in each category:

anova_5$'df' <- c(5-1,50-5,50-1)

# We can estimate the group sum of squares from the mean square:

anova_5$'Sum.of.Squares'[1] <- anova_5$'Mean.Squares'[1] * anova_5$'df'[1]

# We can get the error mean square similarly from the sum of squares:

anova_5$'Mean.Squares'[2] <- anova_5$'Sum.of.Squares'[2] / anova_5$'df'[2]

# The total sum of squares, next...

anova_5$'Sum.of.Squares'[3] <- anova_5$'Sum.of.Squares'[1] + anova_5$'Sum.of.Squares'[2]

# The F ratio, based on the mean squares...

anova_5$'F'[1] <- as.numeric(anova_5$'Mean.Squares'[1])/as.numeric(anova_5$'Mean.Squares'[2])

anova_5$'P'[1] <- pf(as.numeric(anova_5$'F'[1]), df1=anova_5$'df'[1], df2=anova_5$'df'[2], lower.tail=F)

kable(anova_5) %>% kable_styling()

```

Because the p-value we achieved was lower than 0.05, we can reject the null hypothesis that there is no difference in mean values between groups. At least some groups seem meaningfully different from some others. 

<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 
<!-- forced_linebreak -->
&nbsp; 


### 6) More ANOVA Practice

**A study classifies 72 observations into nine groups, with eight observations in each group. The study finds that the variance among the 72 observations is 803. Complete the following ANOVA table:**



```{r}

anova_6 <- data.frame(source = c("Group", "Error", "Total"),
                      'Sum of Squares' = c(6000,NA,NA),
                      'df' = c(NA,NA,NA),
                      'Mean Squares' = c(116.3,NA,NA),
                      F = c(NA,NA,NA),
                      P = c(NA,NA,NA))

kable(anova_6) %>% kable_styling()

```


**With alpha = 0.05, what is your conclusion regarding the null hypothesis that the means of the categories are equal?**

```{r}
# First, lets set the degrees of freedom in each category:

anova_6$'df' <- c(9-1,72-9,72-1)

# We can get the group mean square from the sum of squares:

anova_6$'Mean.Squares'[1] <- anova_6$'Sum.of.Squares'[1] / anova_6$'df'[1]

```

We can use the total variance and the group mean square to find the error mean square: 

\[ S_A^2 = \frac{MS_{groups} - MS_{error}}{n} = Var_{total} - MS_{error} \]
\[ MS_{error} = \frac{n \bullet Var_{total} - MS_{groups}}{n-1} \]

```{r}

anova_6$'Mean.Squares'[2] <- (9*803 - anova_6$'Mean.Squares'[1])/(9-1)

# We can get the error sum of square from the sum of squares:

anova_6$'Sum.of.Squares'[2] <- anova_6$'Mean.Squares'[2] * anova_6$'df'[2]

# The total sum of squares, next...

anova_6$'Sum.of.Squares'[3] <- anova_6$'Sum.of.Squares'[1] + anova_6$'Sum.of.Squares'[2]

# We can estimate the error sum of squares from the mean square:

anova_6$'Sum.of.Squares'[2] <- anova_6$'Mean.Squares'[2] * anova_6$'df'[2]

# The F ratio, based on the mean squares...

anova_6$'F'[1] <- as.numeric(anova_6$'Mean.Squares'[1])/as.numeric(anova_6$'Mean.Squares'[2])

anova_6$'P'[1] <- pf(as.numeric(anova_6$'F'[1]), df1=anova_6$'df'[1], df2=anova_6$'df'[2], lower.tail=F)

kable(anova_6) %>% kable_styling()

```

Because the p-value we achieved was lower than 0.05, we can reject the null hypothesis that there is no difference in mean values between groups. At least some groups seem meaningfully different from some others. 




### 7) Kruskal-Wallis


















